{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabriciocarraro/Google-ADK_AI-Agent-for-social-media/blob/main/Google_ADK_AI_Agent_for_social_media.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-genai google-adk"
      ],
      "metadata": {
        "id": "UCCbECexLk_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82772c7d-e77a-42bd-8988-f6e9fbc845dd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/1.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()"
      ],
      "metadata": {
        "id": "bV4w0H5TLk5g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aePV2bdfDeoW"
      },
      "outputs": [],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types  # Para criar conteúdos (Content e Part)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um serviço de sessão em memória\n",
        "\n",
        "session_service = InMemorySessionService()"
      ],
      "metadata": {
        "id": "-gg0eSx6aRO2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "\n",
        "async def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    # Cria uma nova sessão (você pode personalizar os IDs conforme necessário)\n",
        "    session = await session_service.create_session(app_name=agent.name, user_id=\"user1\")\n",
        "    # Cria um Runner para o agente\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Cria o conteúdo da mensagem de entrada\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "    # Itera assincronamente pelos eventos retornados durante a execução do agente\n",
        "    async for event in runner.run_async(user_id=\"user1\", session_id=session.id, new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "_xP4lWhsS5ko"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista todos os modelos disponíveis atualmente\n",
        "\n",
        "for model in client.models.list():\n",
        "    print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybCS7n_27FOa",
        "outputId": "3ac196f8-3888-498f-d3d2-f3b4fb81885d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/veo-2.0-generate-001\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODELO_RAPIDO = \"gemini-2.0-flash\"\n",
        "MODELO_ROBUSTO = \"gemini-2.5-pro-preview-03-25\""
      ],
      "metadata": {
        "id": "5dPzTt7MOAPX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 1: Buscador de Notícias --- #\n",
        "##########################################\n",
        "\n",
        "async def agente_buscador(topico, data_de_hoje):\n",
        "\n",
        "    buscador = Agent(\n",
        "        name=\"agente_buscador\",\n",
        "        model=MODELO_RAPIDO,\n",
        "        instruction=\"\"\"\n",
        "        Você é um assistente de pesquisa. A sua tarefa é usar a ferramenta de busca do google (google_search)\n",
        "        para recuperar as últimas notícias de lançamentos muito relevantes sobre o tópico abaixo.\n",
        "        Foque em no máximo 5 lançamentos relevantes, com base na quantidade e entusiasmo das notícias sobre ele.\n",
        "        Se um tema tiver poucas notícias ou reações entusiasmadas, é possível que ele não seja tão relevante assim\n",
        "        e pode ser substituído por outro que tenha mais.\n",
        "        Esses lançamentos relevantes devem ser atuais, de no máximo um mês antes da data de hoje.\n",
        "        \"\"\",\n",
        "        description=\"Agente que busca informações no Google\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_buscador = f\"Tópico: {topico}\\nData de hoje: {data_de_hoje}\"\n",
        "\n",
        "    # Executa o agente\n",
        "    lancamentos = await call_agent(buscador, entrada_do_agente_buscador)\n",
        "    return lancamentos"
      ],
      "metadata": {
        "id": "o8bqIfi_DyH8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 2: Planejador de posts --- #\n",
        "################################################\n",
        "\n",
        "async def agente_planejador(topico, lancamentos_buscados):\n",
        "    planejador = Agent(\n",
        "        name=\"agente_planejador\",\n",
        "        model=MODELO_RAPIDO,\n",
        "        instruction=\"\"\"\n",
        "        Você é um planejador de conteúdo, especialista em redes sociais.\n",
        "        Você recebe uma lista de lançamentos recentes do agente buscador e,\n",
        "        - Para cada um dos lançamentos recebidos, você deve usar a ferramenta\n",
        "        de busca do Google (google_search) para buscar os pontos mais relevantes\n",
        "        que poderíamos abordar em um post sobre cada um deles.\n",
        "        Você também pode usar o (google_search) para encontrar mais\n",
        "        informações sobre cada um dos temas e aprofundar.\n",
        "        - Depois de terminar a busca, você irá escolher APENAS UM tema dentre todos eles,\n",
        "        aquele tema com potencial de ser o mais relevante com base nas suas pesquisas.\n",
        "        - Depois de escolher o tema mais relevante dentre todos eles, você irá retornar\n",
        "        qual foi o tema escolhido, seus pontos mais relevantes, e um plano com os assuntos\n",
        "        a serem abordados no post que será escrito posteriormente.\n",
        "        \"\"\",\n",
        "        description=\"Agente que planeja posts\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_planejador = f\"Tópico:{topico}\\nLançamentos buscados: {lancamentos_buscados}\"\n",
        "\n",
        "    # Executa o agente\n",
        "    plano_do_post = await call_agent(planejador, entrada_do_agente_planejador)\n",
        "    return plano_do_post"
      ],
      "metadata": {
        "id": "y3VO1uo5_ghO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# --- Agente 3: Redator do Post --- #\n",
        "######################################\n",
        "\n",
        "async def agente_redator(topico, plano_de_post):\n",
        "    redator = Agent(\n",
        "        name=\"agente_redator\",\n",
        "        model=MODELO_ROBUSTO,\n",
        "        instruction=\"\"\"\n",
        "            Você é um Redator Criativo especializado em criar posts virais para redes sociais.\n",
        "            Você escreve posts para a empresa Alura, a maior escola online de tecnologia do Brasil.\n",
        "            Utilize o tema fornecido no plano de post e os pontos mais relevantes fornecidos e, com base nisso,\n",
        "            escreva um post para Instagram sobre o tema indicado.\n",
        "            O post deve ser engajador, informativo, com linguagem simples e incluir 2 a 4 hashtags no final.\n",
        "            \"\"\",\n",
        "        description=\"Agente redator de posts engajadores para Instagram\"\n",
        "    )\n",
        "    entrada_do_agente_redator = f\"Tópico: {topico}\\nPlano de post: {plano_de_post}\"\n",
        "\n",
        "    # Executa o agente\n",
        "    post_final = await call_agent(redator, entrada_do_agente_redator)\n",
        "    return post_final"
      ],
      "metadata": {
        "id": "uOqlg2TRLVh1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap # Para formatar melhor a saída de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "\n",
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "8dosiodaxfFR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")"
      ],
      "metadata": {
        "id": "SbsI4hCz6sxA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🚀 Iniciando o Sistema de Criação de Posts para Instagram com 3 Agentes 🚀\\n\")\n",
        "\n",
        "# --- Obter o Tópico do Usuário ---\n",
        "topico = input(\"❓ Por favor, digite o TÓPICO sobre o qual você quer criar o post de tendências: \")\n",
        "\n",
        "# Inserir lógica do sistema de agentes\n",
        "if not topico:\n",
        "    print(\"\\nVocê esqueceu de digitar o tópico!\")\n",
        "else:\n",
        "    print(f\"\\nMaravilha! Vamos então criar o post sobre novidades em {topico}\")\n",
        "\n",
        "    lancamentos_buscados = await agente_buscador(topico, data_de_hoje)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 1 (Buscador) ---\\n\")\n",
        "    display(to_markdown(lancamentos_buscados))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    plano_de_post = await agente_planejador(topico, lancamentos_buscados)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 2 (Planejador) ---\\n\")\n",
        "    display(to_markdown(plano_de_post))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    post_redigido = await agente_redator(topico, plano_de_post)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 3 (Redator) ---\\n\")\n",
        "    display(to_markdown(post_redigido))\n",
        "    print(\"--------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xzI6LKzxxnN",
        "outputId": "d5ced309-b6b6-49c3-eb0b-aa5d9570ef30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Iniciando o Sistema de Criação de Posts para Instagram com 3 Agentes 🚀\n",
            "\n",
            "❓ Por favor, digite o TÓPICO sobre o qual você quer criar o post de tendências: lançamentos do evento Google I/O\n",
            "\n",
            "Maravilha! Vamos então criar o post sobre novidades em lançamentos do evento Google I/O\n",
            "\n",
            "--- 📝 Resultado do Agente 1 (Buscador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Para encontrar os lançamentos mais relevantes do Google I/O, farei algumas buscas no Google para identificar os anúncios que geraram mais notícias e entusiasmo no último mês.\n> \n> \n> Com base nas notícias do Google I/O 2025, aqui estão os lançamentos e anúncios mais relevantes, focados em IA e suas aplicações:\n> \n> 1.  **Gemini 2.5 Pro e Flash:** A nova geração dos modelos de IA do Google, com melhorias significativas em raciocínio, velocidade e custo-eficiência. O Gemini 2.5 Pro se destaca como o modelo mais inteligente do Google até o momento, enquanto o Gemini 2.5 Flash é otimizado para tarefas rápidas e econômicas. Ambos estão sendo integrados em diversos produtos, como o aplicativo Gemini, Google Cloud, Chrome e Android.\n> \n> 2.  **AI Mode no Google Search:** Uma nova forma de usar o Google Search, permitindo conversas mais complexas e respostas geradas por IA. O \"Modo IA\" (AI Mode) está sendo disponibilizado nos Estados Unidos e promete entregar resultados mais elaborados, com resumos e comparações gerados a partir de múltiplas fontes. O Google também apresentou o \"Deep Search\" para pesquisas ainda mais aprofundadas.\n> \n> 3.  **Project Astra:** Uma visão de assistente universal, capaz de entender o mundo ao seu redor e interagir de forma contextual. O Project Astra usa o Gemini para compreender vídeo em tempo real, compartilhar tela com contexto, ter memória personalizada e controlar o computador por voz ou texto. Esses recursos estão sendo integrados ao Gemini Live e a novos dispositivos, como óculos com IA.\n> \n> 4.  **Veo 3:** Modelo de IA para geração de vídeos com som nativo e efeitos realistas. O Veo 3 permite criar vídeos a partir de prompts de texto, com sincronização labial, ruídos de fundo contextuais e diálogos integrados. Essa ferramenta está disponível para assinantes do plano Ultra e integrada ao Gemini app e à nova ferramenta Flow.\n> \n> 5.  **Android XR e Project Moohan:** A plataforma Android XR para dispositivos de realidade aumentada e o Project Moohan, um headset desenvolvido em parceria com a Samsung e a Qualcomm. O Android XR promete revolucionar a interação com o mundo digital, enquanto o Project Moohan visa transformar videoconferências em experiências 3D imersivas, utilizando IA para tradução em tempo real e percepção de contexto.\n> \n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n",
            "\n",
            "--- 📝 Resultado do Agente 2 (Planejador) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Okay, com base nos lançamentos do Google I/O 2025 que você me forneceu, vou pesquisar mais informações sobre cada um deles para identificar qual tem o maior potencial para um post de mídia social.\n> \n> \n> Após analisar os lançamentos do Google I/O 2025, o tema que considero mais relevante para um post de mídia social é o **AI Mode no Google Search**.\n> \n> **Justificativa:**\n> \n> *   **Amplo alcance:** O Google Search é usado por bilhões de pessoas diariamente. A introdução do AI Mode tem o potencial de mudar fundamentalmente a forma como as pessoas interagem com a informação online.\n> *   **Novidade:** O lançamento do AI Mode para todos nos Estados Unidos é uma notícia recente e de grande impacto.\n> *   **Discussão:** O tema gera discussões sobre o futuro da busca, o papel da IA na organização da informação e o impacto nos criadores de conteúdo.\n> *   **Recursos:** O AI Mode oferece novas funcionalidades, como conversas mais complexas, respostas geradas por IA e o \"Deep Search\" para pesquisas aprofundadas.\n> \n> **Plano para o Post:**\n> \n> 1.  **Título:** Google Search turbinado por IA: Descubra o AI Mode e o futuro da busca!\n> 2.  **Introdução:**\n>     *   O que é o AI Mode e por que ele é importante.\n>     *   Como o AI Mode muda a forma de pesquisar no Google.\n>     *   O contexto do lançamento no Google I/O 2025.\n> 3.  **Principais recursos do AI Mode:**\n>     *   Conversas complexas com o Google Search.\n>     *   Respostas geradas por IA a partir de múltiplas fontes.\n>     *   O que é o \"Deep Search\" e como ele aprofunda as pesquisas.\n>     *   Integração com o Gemini para funcionalidades como o \"Personal Context\" e sugestões personalizadas.\n> 4.  **Impacto e discussão:**\n>     *   Como o AI Mode pode afetar a forma como as pessoas aprendem e encontram informação.\n>     *   O impacto para criadores de conteúdo e SEO.\n>     *   Privacidade e uso de dados pessoais pelo AI Mode.\n> 5.  **Chamada para ação:**\n>     *   Incentivar os usuários a experimentar o AI Mode (se disponível em sua região).\n>     *   Convidar os seguidores a compartilhar suas opiniões e experiências com a nova ferramenta.\n> \n> **Possíveis formatos:**\n> \n> *   Post de texto com imagens e GIFs explicativos.\n> *   Vídeo curto demonstrando o AI Mode em ação.\n> *   Enquete para saber a opinião dos seguidores sobre o futuro da busca com IA.\n> \n> Este plano oferece uma abordagem completa e informativa sobre o AI Mode no Google Search, explorando seus recursos, impacto e potencial para o futuro da busca online.\n> \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n",
            "\n",
            "--- 📝 Resultado do Agente 3 (Redator) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Okay, Alura! Preparei um post caprichado sobre o AI Mode no Google Search, direto do forno do Google I/O 2025. A ideia é deixar a galera curiosa e mostrar como a busca que a gente conhece está evoluindo! 🚀\n> \n> ---\n> \n> ✨ **O Google Search NUNCA MAIS SERÁ O MESMO!** ✨\n> \n> E aí, dev & curioso por tecnologia! 👋 Você piscou e o Google I/O 2025 chegou com uma bomba: o **AI Mode no Google Search**! 🤯 Sabe aquela busca tradicional? Esquece! Estamos falando de uma revolução na forma como encontramos informação.\n> \n> Mas calma, o que é esse tal de AI Mode? 🤔\n> É o Google Search turbinado com Inteligência Artificial, permitindo:\n> \n> *   🗣️ **Conversas complexas:** Faça perguntas elaboradas como se estivesse batendo um papo com um expert. Chega de palavras-chave soltas!\n> *   🧠 **Respostas geradas por IA:** Em vez de só links, receba resumos inteligentes e completos, compilados de diversas fontes.\n> *   🔎 **\"Deep Search\":** Quer mergulhar de cabeça em um assunto? Essa função te leva para as profundezas do conhecimento, organizando informações complexas de forma clara.\n> *   🔮 **Integração com Gemini:** Espere por contexto pessoal e sugestões personalizadas que entendem VOCÊ!\n> \n> **O impacto? Gigante!** 💥\n> Isso muda como aprendemos, como criamos conteúdo e até o SEO que conhecemos. A IA está reorganizando o conhecimento mundial, e na Alura, a gente AMA ver a tecnologia transformando o futuro!\n> \n> E aí, preparado(a) para essa nova era da busca? O AI Mode já está sendo lançado nos EUA! 🇺🇸\n> \n> 👇 Conta pra gente: qual sua expectativa para essa novidade? Como você acha que o AI Mode vai impactar seu dia a dia e seus estudos?\n> \n> #GoogleIO #InteligenciaArtificial #FuturoDaBusca #AluraOnline\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}